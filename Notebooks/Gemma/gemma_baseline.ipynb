{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4b7541",
   "metadata": {},
   "source": [
    "In this notebook we evaluate performance of pretrained Gemma model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac553165",
   "metadata": {},
   "source": [
    "# PREREQUISITES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a316eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GemmaForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import GemmaTokenizerFast\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64843b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70a3e44d07f4aa4a06f8ea8b8fa4f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26601cf9",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bad7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        heading_text  bias_rating\n",
      "0  chicago gun violence spikes and increasingly f...            0\n",
      "1  'bullets just came from nowhere': fourth of ju...            1\n",
      "2  dozens of shootings across us mark bloody july...            2\n",
      "3  federal government will run out of cash on oct...            2\n",
      "4  yellen tells congress that u.s. will run out o...            0\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd() # get current directory\n",
    "file_path = os.path.join(current_directory, '..', '..', 'data', 'processed', 'clean_data.csv') # navigate to folder with preprocessed data\n",
    "data = pd.read_csv(file_path)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60712f26",
   "metadata": {},
   "source": [
    "# Split and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48df50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['heading_text'].values\n",
    "y = data['bias_rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fc08498",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GemmaTokenizerFast.from_pretrained('google/gemma-2b')\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "675369d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    We need this class to manage and load\n",
    "    encoded inputs and corresponding labels into a format compatible\n",
    "    with PyTorch's DataLoader for model training and evaluation :)\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = NewsDataset(train_encodings, y_train)\n",
    "test_dataset = NewsDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea25f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6166ae4",
   "metadata": {},
   "source": [
    "# Load the model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id  = \"google/gemma-2b-it\"\n",
    "\n",
    "\n",
    "model = GemmaForSequenceClassification.from_pretrained(\n",
    "    model_id, \n",
    "    num_labels = 3,\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fc5c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3686d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "396e5eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/s5153484/venvs/my_env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_baseline\",     \n",
    "    per_device_eval_batch_size=16,   \n",
    "    logging_dir=\"./logs_baseline\",       \n",
    "    do_train=False,                  # Disable training\n",
    "    do_eval=True,                    \n",
    "    evaluation_strategy=\"epoch\",    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49c9e6",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5d29988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/272 03:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance: {'eval_loss': 1.9030852317810059, 'eval_model_preparation_time': 0.0058, 'eval_accuracy': 0.3770981834904576, 'eval_precision': 0.3860343863973383, 'eval_recall': 0.3770981834904576, 'eval_f1': 0.3110451359867519, 'eval_runtime': 227.0357, 'eval_samples_per_second': 19.156, 'eval_steps_per_second': 1.198}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print baseline performance\n",
    "print(\"Baseline performance:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88cfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
